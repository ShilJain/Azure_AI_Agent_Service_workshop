{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent 2: Forecaster\n",
    "**`Forecaster`** is an agent focused on forecasting future electricity consumption plan based on historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load environment variables from the .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import Any, Optional, Literal, Set, Callable\n",
    "from nixtla import NixtlaClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the forecast_consumption function\n",
    "def forecast_consumption() -> str:\n",
    "    \"\"\"\n",
    "    Forecast electricity consumption        \n",
    "    :return: json of forecasted consumption\n",
    "    \n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    \n",
    "    #Initialize the Nixtla client with the TimeGEN API key and endpoint\n",
    "    \n",
    "    nixtla_client = NixtlaClient(\n",
    "        base_url=os.getenv(\"TIME_GEN_ENDPOINT\"),\n",
    "        api_key=os.getenv(\"TIME_GEN_KEY\"),\n",
    "    )\n",
    "    consumption = pd.read_csv('./data/consumption.csv')\n",
    "    forecasted_consumption = nixtla_client.forecast(df=consumption, h=12, freq='MS', time_col='month', target_col='consumption')               \n",
    "    forecasted_consumption['month'] = forecasted_consumption['month'].astype(str)\n",
    "    \n",
    "    return forecasted_consumption.to_json(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:azure.identity._credentials.environment:No environment configuration found.\n",
      "INFO:azure.identity._credentials.managed_identity:ManagedIdentityCredential will use IMDS\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects.models import FunctionTool\n",
    "\n",
    "# Create a project client\n",
    "\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(), conn_str=os.environ[\"PROJECT_CONNECTION_STRING\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'function', 'function': {'name': 'forecast_consumption', 'description': 'Forecast electricity consumption        ', 'parameters': {'type': 'object', 'properties': {}, 'required': []}}}]\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Set, Callable\n",
    "from azure.ai.projects.models import FunctionTool\n",
    "\n",
    "# Define function tool with the forecast_consumption function\n",
    "user_functions: Set[Callable[..., Any]] = {forecast_consumption}\n",
    "functions = FunctionTool(functions=user_functions)\n",
    "print(functions.definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "# Set the logging level for the Azure SDK\n",
    "logging.getLogger('azure.core.pipeline.policies.http_logging_policy').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent, agent ID: asst_01PlD0q8fH1Yzdg4qde8WVB4\n"
     ]
    }
   ],
   "source": [
    "# Create an agent \n",
    "data_analyzer = project_client.agents.create_agent(\n",
    "    model=os.environ[\"AZURE_OPENAI_DEPLOYMENT\"],\n",
    "    name=\"forecast\",\n",
    "    description=\"An agent that forecasts electricity consumption\",\n",
    "    instructions=\"Hello, you are helpful assistant who answers question on future electricity consumption.\",\n",
    "    tools=functions.definitions,\n",
    "    # Parameters\n",
    "    temperature=0.5,\n",
    "    top_p=0.95,\n",
    "    \n",
    ")\n",
    "\n",
    "print(f\"Created agent, agent ID: {data_analyzer.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created thread, ID: thread_tq54nD7mYKFMVDUjhhqxp2VR\n",
      "Created run, ID: run_eRvDSydAdWnK7cKUORqdfNZz\n",
      "Executing tool call: {'id': 'call_O0SaXiXkYeRkJ6BAr99l6L9U', 'type': 'function', 'function': {'name': 'forecast_consumption', 'arguments': '{}'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shilpajain\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nixtla\\nixtla_client.py:867: UserWarning: Azure endpoint detected, setting `model` to 'azureai'.\n",
      "  warnings.warn(\"Azure endpoint detected, setting `model` to 'azureai'.\")\n",
      "INFO:nixtla.nixtla_client:Validating inputs...\n",
      "INFO:nixtla.nixtla_client:Preprocessing dataframes...\n",
      "INFO:nixtla.nixtla_client:Querying model metadata...\n",
      "INFO:nixtla.nixtla_client:Restricting input...\n",
      "INFO:nixtla.nixtla_client:Calling Forecast Endpoint...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool outputs: [{'tool_call_id': 'call_O0SaXiXkYeRkJ6BAr99l6L9U', 'output': '[{\"month\":\"2025-01-01\",\"TimeGPT\":635.0912475586},{\"month\":\"2025-02-01\",\"TimeGPT\":570.1800537109},{\"month\":\"2025-03-01\",\"TimeGPT\":626.5328369141},{\"month\":\"2025-04-01\",\"TimeGPT\":649.0748901367},{\"month\":\"2025-05-01\",\"TimeGPT\":661.8880004883},{\"month\":\"2025-06-01\",\"TimeGPT\":679.6558837891},{\"month\":\"2025-07-01\",\"TimeGPT\":634.1744995117},{\"month\":\"2025-08-01\",\"TimeGPT\":661.2553710938},{\"month\":\"2025-09-01\",\"TimeGPT\":667.4523925781},{\"month\":\"2025-10-01\",\"TimeGPT\":609.4385986328},{\"month\":\"2025-11-01\",\"TimeGPT\":725.0209960938},{\"month\":\"2025-12-01\",\"TimeGPT\":644.9719238281}]'}]\n",
      "Current run status: RunStatus.REQUIRES_ACTION\n",
      "Current run status: RunStatus.IN_PROGRESS\n",
      "Current run status: RunStatus.COMPLETED\n",
      "Run completed with status: RunStatus.COMPLETED\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from azure.ai.projects.models import RequiredFunctionToolCall, SubmitToolOutputsAction, ToolOutput\n",
    "\n",
    "# Create a thread\n",
    "thread = project_client.agents.create_thread()\n",
    "print(f\"Created thread, ID: {thread.id}\")\n",
    "\n",
    "# Create message to thread\n",
    "message = project_client.agents.create_message(\n",
    "    thread_id=thread.id, role=\"user\", content=\"Hello, what would be my electricity consumption in next 12 months.\"\n",
    ")\n",
    "\n",
    "# Create and process assistant run in thread with tools\n",
    "run = project_client.agents.create_run(\n",
    "    thread_id=thread.id, assistant_id=data_analyzer.id)\n",
    "print(f\"Created run, ID: {run.id}\")\n",
    "\n",
    "while run.status in [\"queued\", \"in_progress\", \"requires_action\"]:\n",
    "    time.sleep(1)\n",
    "    run = project_client.agents.get_run(thread_id=thread.id, run_id=run.id)\n",
    "\n",
    "    if run.status == \"requires_action\" and isinstance(run.required_action, SubmitToolOutputsAction):\n",
    "        tool_calls = run.required_action.submit_tool_outputs.tool_calls\n",
    "        if not tool_calls:\n",
    "            print(\"No tool calls provided - cancelling run\")\n",
    "            project_client.agents.cancel_run(\n",
    "                thread_id=thread.id, run_id=run.id)\n",
    "            break\n",
    "\n",
    "        tool_outputs = []\n",
    "        for tool_call in tool_calls:\n",
    "            if isinstance(tool_call, RequiredFunctionToolCall):\n",
    "                try:\n",
    "                    print(f\"Executing tool call: {tool_call}\")\n",
    "                    output = functions.execute(tool_call)\n",
    "                    tool_outputs.append(\n",
    "                        ToolOutput(\n",
    "                            tool_call_id=tool_call.id,\n",
    "                            output=output,\n",
    "                        )\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"Error executing tool_call {tool_call.id}: {e}\")\n",
    "\n",
    "        print(f\"Tool outputs: {tool_outputs}\")\n",
    "        if tool_outputs:\n",
    "            project_client.agents.submit_tool_outputs_to_run(\n",
    "                thread_id=thread.id, run_id=run.id, tool_outputs=tool_outputs\n",
    "            )\n",
    "\n",
    "    print(f\"Current run status: {run.status}\")\n",
    "\n",
    "print(f\"Run completed with status: {run.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "\n",
    "from datetime import datetime\n",
    "def get_conversation_md(conversation):\n",
    "    \"\"\"\n",
    "    Function to return a conversation in Markdown (MD) format as a string.\n",
    "    \"\"\"\n",
    "    messages = conversation.get(\"data\", [])\n",
    "    if not messages:\n",
    "        return \"No messages found in the conversation.\"\n",
    "\n",
    "    # Initialize a list to hold the Markdown lines\n",
    "    md_lines = []\n",
    "    md_lines.append(\"# Conversation\")\n",
    "    md_lines.append(\"___\")  # Markdown horizontal line\n",
    "\n",
    "    # Iterate through the messages\n",
    "    # Reversing to maintain chronological order\n",
    "    for message in reversed(messages):\n",
    "        role = message.get(\"role\", \"unknown\").capitalize()\n",
    "        timestamp = message.get(\"created_at\")\n",
    "        content = message.get(\"content\", [])\n",
    "\n",
    "        # Convert timestamp to a readable format\n",
    "        if timestamp:\n",
    "            timestamp = datetime.fromtimestamp(\n",
    "                timestamp).astimezone().strftime('%Y-%m-%d %H:%M:%S %Z')\n",
    "        else:\n",
    "            timestamp = \"Unknown time\"\n",
    "\n",
    "        # Extract the text content\n",
    "        message_text = \"\"\n",
    "        for item in content:\n",
    "            if item.get(\"type\") == \"text\":\n",
    "                message_text += item[\"text\"].get(\"value\", \"\")\n",
    "\n",
    "        # Append the message in Markdown format\n",
    "        md_lines.append(f\"### **{role}** ({timestamp})\")\n",
    "        md_lines.append(f\"{message_text}\")\n",
    "        md_lines.append(\"___\")  # Markdown horizontal line\n",
    "\n",
    "    # Join the lines with newlines to form the complete Markdown string\n",
    "    return \"\\n\".join(md_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Conversation\n",
       "___\n",
       "### **User** (2025-02-08 00:28:37 Malay Peninsula Standard Time)\n",
       "Hello, what would be my electricity consumption in next 12 months.\n",
       "___\n",
       "### **Assistant** (2025-02-08 00:28:54 Malay Peninsula Standard Time)\n",
       "Here is the forecast of your electricity consumption for the next 12 months:\n",
       "\n",
       "- January 2025: 635.09 kWh\n",
       "- February 2025: 570.18 kWh\n",
       "- March 2025: 626.53 kWh\n",
       "- April 2025: 649.07 kWh\n",
       "- May 2025: 661.89 kWh\n",
       "- June 2025: 679.66 kWh\n",
       "- July 2025: 634.17 kWh\n",
       "- August 2025: 661.26 kWh\n",
       "- September 2025: 667.45 kWh\n",
       "- October 2025: 609.44 kWh\n",
       "- November 2025: 725.02 kWh\n",
       "- December 2025: 644.97 kWh\n",
       "\n",
       "This forecast is based on historical data and other relevant factors.\n",
       "___"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "\n",
    "display(Markdown(get_conversation_md(messages)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
